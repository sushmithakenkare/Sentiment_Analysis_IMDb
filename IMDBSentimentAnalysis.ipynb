{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis on IMDb Large Movie Review Dataset using Natural Language Processing (NLP). \n",
    "\n",
    "#Importing the required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important Note: \n",
    "The Large Reviews Dataset consists of train and test datasets, each with 25k reviews including positive and negative reviews that are present as multiple text files. \n",
    "These text files are merged into full_train.txt and full_test.txt (which we have used in this code) using shell commands mentioned in 'combine.docx' word document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the datasets\n",
    "reviews_train = []\n",
    "for line in open('full_train.txt', 'r', encoding = \"utf-8\"):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('full_test.txt', 'r', encoding = \"utf-8\"):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my  years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning: Removing punctuation and HTML tags and making everything to lower-case for easy processing \n",
    "#We are using regular expressions/pattern matching approach\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "reviews = []\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "reviews_train_clean[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sushmitha\n",
      "[nltk_data]     Kenkare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Data Preparation\n",
    "#Text Preprocessing\n",
    "\n",
    "#1.Removing Stop words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = ['in','of','at','a','the']\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "no_stop_words = remove_stop_words(reviews_train_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"bromwel high is a cartoon comedi it ran at the same time as some other program about school life such as teacher my year in the teach profess lead me to believ that bromwel high' satir is much closer to realiti than is teacher the scrambl to surviv financi the insight student who can see right through their pathet teachers' pomp the petti of the whole situat all remind me of the school i knew and their student when i saw the episod in which a student repeatedli tri to burn down the school i immedi recal at high a classic line inspector i'm here to sack one of your teacher student welcom to bromwel high i expect that mani adult of my age think that bromwel high is far fetch what a piti that it isn't\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Normalization \n",
    "\n",
    "#Stemming \n",
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sushmitha\n",
      "[nltk_data]     Kenkare\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"bromwell high is a cartoon comedy it ran at the same time a some other program about school life such a teacher my year in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teacher the scramble to survive financially the insightful student who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the school i knew and their student when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teacher student welcome to bromwell high i expect that many adult of my age think that bromwell high is far fetched what a pity that it isn't\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization \n",
    "\n",
    "nltk.download('wordnet')\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words \n",
    "# Initialize a bag of words  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 500) \n",
    "\n",
    "# Fit transform the data\n",
    "X = vectorizer.fit_transform(reviews_train_clean).toarray()\n",
    "X_val = vectorizer.transform(reviews_test_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'are',\n",
       " 'around',\n",
       " 'art',\n",
       " 'as',\n",
       " 'at',\n",
       " 'audience',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'based',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'book',\n",
       " 'boring',\n",
       " 'both',\n",
       " 'boy',\n",
       " 'budget',\n",
       " 'but',\n",
       " 'by',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'car',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'certainly',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'child',\n",
       " 'children',\n",
       " 'cinema',\n",
       " 'classic',\n",
       " 'close',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'completely',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'definitely',\n",
       " 'despite',\n",
       " 'dialogue',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'direction',\n",
       " 'director',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'drama',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'each',\n",
       " 'early',\n",
       " 'effects',\n",
       " 'either',\n",
       " 'else',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enough',\n",
       " 'entertaining',\n",
       " 'entire',\n",
       " 'episode',\n",
       " 'especially',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'evil',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'far',\n",
       " 'father',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'film',\n",
       " 'films',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'flick',\n",
       " 'for',\n",
       " 'found',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'game',\n",
       " 'gave',\n",
       " 'genre',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'had',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heart',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hollywood',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'horror',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'human',\n",
       " 'humor',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'in',\n",
       " 'instead',\n",
       " 'interesting',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'job',\n",
       " 'john',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'last',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'left',\n",
       " 'less',\n",
       " 'let',\n",
       " 'life',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'low',\n",
       " 'made',\n",
       " 'main',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'men',\n",
       " 'michael',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'minutes',\n",
       " 'moments',\n",
       " 'money',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'music',\n",
       " 'must',\n",
       " 'my',\n",
       " 'name',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'original',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'part',\n",
       " 'past',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'performance',\n",
       " 'performances',\n",
       " 'perhaps',\n",
       " 'person',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'place',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playing',\n",
       " 'plays',\n",
       " 'plot',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'pretty',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'production',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'read',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'recommend',\n",
       " 'remember',\n",
       " 'rest',\n",
       " 'right',\n",
       " 'role',\n",
       " 'run',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'scene',\n",
       " 'scenes',\n",
       " 'school',\n",
       " 'screen',\n",
       " 'script',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'sense',\n",
       " 'series',\n",
       " 'set',\n",
       " 'several',\n",
       " 'sex',\n",
       " 'she',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'should',\n",
       " 'show',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'small',\n",
       " 'so',\n",
       " 'some',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'son',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'special',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'starts',\n",
       " 'still',\n",
       " 'story',\n",
       " 'stupid',\n",
       " 'style',\n",
       " 'such',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'takes',\n",
       " 'tell',\n",
       " 'terrible',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'times',\n",
       " 'title',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'totally',\n",
       " 'town',\n",
       " 'tries',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'turns',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'under',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'until',\n",
       " 'up',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 've',\n",
       " 'version',\n",
       " 'very',\n",
       " 'video',\n",
       " 'viewer',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'war',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'waste',\n",
       " 'watch',\n",
       " 'watched',\n",
       " 'watching',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'white',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wife',\n",
       " 'will',\n",
       " 'with',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'won',\n",
       " 'wonderful',\n",
       " 'work',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.74828\n",
      "F1 score: 0.7475471155429844\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10027  2473]\n",
      " [ 3820  8680]]\n"
     ]
    }
   ],
   "source": [
    "# Split data to test preprocessing and modeling techniques\n",
    "X_train, X_test, y_train, y_val = train_test_split(X, target,train_size=0.75)\n",
    "    \n",
    "final_rf = RandomForestClassifier(n_estimators = 10)\n",
    "final_rf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_rf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_rf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_rf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.84216\n",
      "F1 score: 0.8421413135727094\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10391  2109]\n",
      " [ 1837 10663]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "    \n",
    "final_log = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "final_log.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_log.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_log.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_log.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.78552\n",
      "F1 score: 0.7854882810959772\n",
      "\n",
      " Confusion Matrix:\n",
      " [[9971 2529]\n",
      " [2833 9667]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "    \n",
    "final_nb = MultinomialNB()\n",
    "final_nb.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_nb.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_nb.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_nb.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.83728\n",
      "F1 score: 0.8372291206878945\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10687  1813]\n",
      " [ 2255 10245]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "    \n",
    "final_svm = LinearSVC(max_iter=1500)\n",
    "final_svm.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_svm.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_svm.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_svm.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.69312\n",
      "F1 score: 0.6931154748035454\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8712 3788]\n",
      " [3884 8616]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree classifier\n",
    "    \n",
    "final_dec = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "final_dec.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_dec.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_dec.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_dec.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89944\n",
      "F1 score: 0.8994371964699379\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11177  1323]\n",
      " [ 1191 11309]]\n"
     ]
    }
   ],
   "source": [
    "#n-gram feature extraction\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words = stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_val = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "    \n",
    "final_ngram = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.76076\n",
      "F1 score: 0.7599151745348601\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10251  2249]\n",
      " [ 3732  8768]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "    \n",
    "final_ngram = RandomForestClassifier(n_estimators = 10)\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88164\n",
      "F1 score: 0.8814567246992848\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11512   988]\n",
      " [ 1971 10529]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "    \n",
    "final_ngram = MultinomialNB()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89904\n",
      "F1 score: 0.8814567246992848\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11512   988]\n",
      " [ 1971 10529]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "final = LinearSVC(max_iter=1500)\n",
    "final.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.724\n",
      "F1 score: 0.7239999841023991\n",
      "\n",
      " Confusion Matrix:\n",
      " [[9053 3447]\n",
      " [3453 9047]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "    \n",
    "final_ngram = DecisionTreeClassifier()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.86748\n",
      "F1 score: 0.867471088756008\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10946  1554]\n",
      " [ 1759 10741]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, \n",
    ")\n",
    "    \n",
    "final_wc = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7462\n",
      "F1 score: 0.7449488205258901\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10203  2297]\n",
      " [ 4048  8452]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "    \n",
    "final_wc = RandomForestClassifier(n_estimators = 10)\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.81512\n",
      "F1 score: 0.8143538797494231\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10992  1508]\n",
      " [ 3114  9386]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "    \n",
    "final_wc = MultinomialNB()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.84588\n",
      "F1 score: 0.8458613492232561\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10711  1789]\n",
      " [ 2064 10436]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "final_wc = LinearSVC(max_iter=1500)\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.71008\n",
      "F1 score: 0.7100792578029002\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8896 3604]\n",
      " [3644 8856]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "   \n",
    "final_wc = DecisionTreeClassifier()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88204\n",
      "F1 score: 0.8820396510261037\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11047  1453]\n",
      " [ 1496 11004]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_val = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "    \n",
    "final_tfidf = LogisticRegression()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.73056\n",
      "F1 score: 0.728656323969551\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10179  2321]\n",
      " [ 4415  8085]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "    \n",
    "final_tfidf = RandomForestClassifier(n_estimators = 10)\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.83024\n",
      "F1 score: 0.8295866203788163\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11152  1348]\n",
      " [ 2896  9604]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "    \n",
    "final_tfidf = MultinomialNB()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87704\n",
      "F1 score: 0.8770245739625577\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11103  1397]\n",
      " [ 1677 10823]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "    \n",
    "final_tfidf = LinearSVC()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.70488\n",
      "F1 score: 0.704879771458895\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8800 3700]\n",
      " [3678 8822]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "    \n",
    "final_tfidf = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining regular expression for preprocessing\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the train and test data sets\n",
    "def load():\n",
    "\treviews_train = []\n",
    "\tfor line in open('full_train.txt', 'r', encoding = \"utf8\"):\n",
    "\t\treviews_train.append(line.strip())\n",
    "\n",
    "\treviews_test = []\n",
    "\tfor line in open('full_test.txt', 'r', encoding = \"utf8\"):\n",
    "\t    reviews_test.append(line.strip())\n",
    "\n",
    "\treturn(reviews_train,reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean up the cluttered review set\n",
    "def preprocess_reviews(reviews):\n",
    "\treviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "\treviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\treturn reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test human generated review for cross validation\n",
    "\n",
    "def test_new_review(final_model,cv):\n",
    "    \n",
    "    while True:\n",
    "        pred = final_model.predict(cv.transform([input(\"Check Your Own Review :\")]))[0]\n",
    "        if(pred == 0):\n",
    "            print(\"Negative Review!\")\n",
    "            a = input(\"Do you want to continue?[Y/N]:\").lower()\n",
    "            if a ==\"y\":\n",
    "                test_new_review(final_model,cv)\n",
    "            elif a==\"n\":\n",
    "                break\n",
    "        else:\n",
    "            print(\"Positive Review!\")\n",
    "            a = input(\"Do you want to continue?[Y/N]:\").lower()\n",
    "            if a ==\"y\":\n",
    "                test_new_review(final_model,cv)\n",
    "            elif a==\"n\":\n",
    "                break\n",
    "    \n",
    "    print(\"GoodBye!\")\n",
    "    quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to give example of some positive and negative tokens\n",
    "def token_example(feature_to_coef):\n",
    "\tprint(\"Example of some positive words and their weightage:\")\n",
    "\tfor best_positive in sorted(\n",
    "\t    feature_to_coef.items(), \n",
    "\t    key=lambda x: x[1], \n",
    "\t    reverse=True)[:5]:\n",
    "\t    print (best_positive)\n",
    "    \n",
    "\tprint(\"Example of some negative words and their weightage\")\n",
    "\tfor best_negative in sorted(\n",
    "\t    feature_to_coef.items(), \n",
    "\t    key=lambda x: x[1])[:5]:\n",
    "\t    print (best_negative)\n",
    "\n",
    "def Regularisation_parameter(X_train, y_train, y_val, X_val):\n",
    "\tz = 0\n",
    "\tfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "\t    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=1000)\n",
    "\t    lr.fit(X_train, y_train)\n",
    "\t    print (\"Accuracy for C=%s: %s\" \n",
    "\t           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\t    if(z < accuracy_score(y_val, lr.predict(X_val))):\n",
    "\t    \tz = accuracy_score(y_val, lr.predict(X_val))\n",
    "\t\n",
    "\treturn z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.86704\n",
      "Accuracy for C=0.05: 0.87664\n",
      "Accuracy for C=0.25: 0.87472\n",
      "Accuracy for C=0.5: 0.87328\n",
      "Accuracy for C=1: 0.8712\n",
      "Final Accuracy: 0.87008\n",
      "Example of some positive words and their weightage:\n",
      "('excellent', 1.5291790338605942)\n",
      "('refreshing', 1.4764307717726397)\n",
      "('perfect', 1.3507169574739248)\n",
      "('appreciated', 1.3389001046838678)\n",
      "('superb', 1.3027981975619096)\n",
      "Example of some negative words and their weightage\n",
      "('worst', -2.2955474361954353)\n",
      "('waste', -2.1342313303990426)\n",
      "('disappointment', -1.938409888254895)\n",
      "('poorly', -1.9148824673258413)\n",
      "('awful', -1.7183549900412898)\n",
      "Check Your Own Review :Horrible\n",
      "Negative Review!\n",
      "Do you want to continue?[Y/N]:Y\n",
      "Check Your Own Review :Very good movie\n",
      "Positive Review!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\t#loading the train and test data sets\n",
    "\treviews_train,reviews_test = load()\n",
    "\n",
    "\t#preprocessing the given data\n",
    "\treviews_train_clean = preprocess_reviews(reviews_train)\n",
    "\treviews_test_clean = preprocess_reviews(reviews_test)\n",
    "\n",
    "\n",
    "\t#vectorization of the reviews\n",
    "\tcv = CountVectorizer(binary=True)\n",
    "\tcv.fit(reviews_train_clean) \n",
    "\tX = cv.transform(reviews_train_clean) # will give a sparse matrix find a way to make this efficient\n",
    "\tX_test = cv.transform(reviews_test_clean)\n",
    "\ttarget = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "\n",
    "\t#splitting the train and test data\n",
    "\tX_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "\n",
    "\t#choosing the regularisaton parameter (logistic regression) for the greatest accuracy value\n",
    "\tbest_c_value = Regularisation_parameter(X_train, y_train, y_val, X_val)\n",
    "\n",
    "\t#training the final logistic model for the best accuracy\n",
    "\tfinal_model = LogisticRegression(C=best_c_value, solver='lbfgs', max_iter=1000)\n",
    "\tfinal_model.fit(X, target)\n",
    "\tprint (\"Final Accuracy: %s\" % accuracy_score(target, final_model.predict(X_test)))\n",
    "\n",
    "\tfeature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "\t}\n",
    "\n",
    "    #example of pos and neg sentiment\n",
    "\ttoken_example(feature_to_coef) \n",
    "\t\n",
    "\twhile(True):\n",
    "\t\ttest_new_review(final_model,cv) #checking the model with human data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion from comparing the results: Logistic Regression performs better acrosss all feature extraction methods. \n",
    "For more details: refer to the report document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
