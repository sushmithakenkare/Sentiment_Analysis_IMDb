{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis on Large Movie Review Dataset using NLP\n",
    "\n",
    "#Importing the required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The reviews dataset had train and test datasets, each with 25k reviews including positive and negative reviews.\n",
    "#The reviews were present as multiple text files which have been merged into full_train.txt and full_test.txt using the shell commands as mentioned in the word document.\n",
    "#Loading the datasets\n",
    "reviews_train = []\n",
    "for line in open('/Users/navyasogi/Desktop/ML_Coursework/ProjectSubmission_2_Group10/movie_data/full_train.txt', 'r'):\n",
    "    \n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open('/Users/navyasogi/Desktop/ML_Coursework/ProjectSubmission_2_Group10/movie_data/full_test.txt', 'r'):\n",
    "    \n",
    "    reviews_test.append(line.strip())\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my  years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data cleaning: Removing punctuation and HTML tags and making everything to lower-case for easy processing \n",
    "#We are using regular expressions/pattern matching approach\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "reviews = []\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)\n",
    "reviews_train_clean[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation\n",
    "#Text Preprocessing\n",
    "#1.Removing Stop words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "english_stop_words = stopwords.words('english')\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = ['in','of','at','a','the']\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in english_stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "no_stop_words = remove_stop_words(reviews_train_clean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"bromwel high is a cartoon comedi it ran at the same time as some other program about school life such as teacher my year in the teach profess lead me to believ that bromwel high' satir is much closer to realiti than is teacher the scrambl to surviv financi the insight student who can see right through their pathet teachers' pomp the petti of the whole situat all remind me of the school i knew and their student when i saw the episod in which a student repeatedli tri to burn down the school i immedi recal at high a classic line inspector i'm here to sack one of your teacher student welcom to bromwel high i expect that mani adult of my age think that bromwel high is far fetch what a piti that it isn't\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Normalization \n",
    "#Stemming \n",
    "def get_stemmed_text(corpus):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "stemmed_reviews = get_stemmed_text(reviews_train_clean)\n",
    "stemmed_reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/navyasogi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"bromwell high is a cartoon comedy it ran at the same time a some other program about school life such a teacher my year in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teacher the scramble to survive financially the insightful student who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the school i knew and their student when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teacher student welcome to bromwell high i expect that many adult of my age think that bromwell high is far fetched what a pity that it isn't\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization \n",
    "nltk.download('wordnet')\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "lemmatized_reviews = get_lemmatized_text(reviews_train_clean)\n",
    "lemmatized_reviews[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words \n",
    "# Initialize a bag of words  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 500) \n",
    "\n",
    "# Fit transform the data\n",
    "X = vectorizer.fit_transform(reviews_train_clean).toarray()\n",
    "X_val = vectorizer.transform(reviews_test_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'american',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'are',\n",
       " 'around',\n",
       " 'art',\n",
       " 'as',\n",
       " 'at',\n",
       " 'audience',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'based',\n",
       " 'be',\n",
       " 'beautiful',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'black',\n",
       " 'book',\n",
       " 'boring',\n",
       " 'both',\n",
       " 'boy',\n",
       " 'budget',\n",
       " 'but',\n",
       " 'by',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'car',\n",
       " 'care',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'certainly',\n",
       " 'character',\n",
       " 'characters',\n",
       " 'child',\n",
       " 'children',\n",
       " 'cinema',\n",
       " 'classic',\n",
       " 'close',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comes',\n",
       " 'completely',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'definitely',\n",
       " 'despite',\n",
       " 'dialogue',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'direction',\n",
       " 'director',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'drama',\n",
       " 'during',\n",
       " 'dvd',\n",
       " 'each',\n",
       " 'early',\n",
       " 'effects',\n",
       " 'either',\n",
       " 'else',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'enjoy',\n",
       " 'enjoyed',\n",
       " 'enough',\n",
       " 'entertaining',\n",
       " 'entire',\n",
       " 'episode',\n",
       " 'especially',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'evil',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'far',\n",
       " 'father',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'film',\n",
       " 'films',\n",
       " 'final',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'first',\n",
       " 'flick',\n",
       " 'for',\n",
       " 'found',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funny',\n",
       " 'game',\n",
       " 'gave',\n",
       " 'genre',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'had',\n",
       " 'half',\n",
       " 'hand',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heart',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'history',\n",
       " 'hollywood',\n",
       " 'home',\n",
       " 'hope',\n",
       " 'horror',\n",
       " 'house',\n",
       " 'how',\n",
       " 'however',\n",
       " 'human',\n",
       " 'humor',\n",
       " 'idea',\n",
       " 'if',\n",
       " 'in',\n",
       " 'instead',\n",
       " 'interesting',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'job',\n",
       " 'john',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'know',\n",
       " 'last',\n",
       " 'later',\n",
       " 'laugh',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'left',\n",
       " 'less',\n",
       " 'let',\n",
       " 'life',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'live',\n",
       " 'lives',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'loved',\n",
       " 'low',\n",
       " 'made',\n",
       " 'main',\n",
       " 'make',\n",
       " 'makes',\n",
       " 'making',\n",
       " 'man',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'men',\n",
       " 'michael',\n",
       " 'might',\n",
       " 'mind',\n",
       " 'minutes',\n",
       " 'moments',\n",
       " 'money',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'movie',\n",
       " 'movies',\n",
       " 'mr',\n",
       " 'much',\n",
       " 'music',\n",
       " 'must',\n",
       " 'my',\n",
       " 'name',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'original',\n",
       " 'other',\n",
       " 'others',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'part',\n",
       " 'past',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'performance',\n",
       " 'performances',\n",
       " 'perhaps',\n",
       " 'person',\n",
       " 'picture',\n",
       " 'piece',\n",
       " 'place',\n",
       " 'play',\n",
       " 'played',\n",
       " 'playing',\n",
       " 'plays',\n",
       " 'plot',\n",
       " 'point',\n",
       " 'poor',\n",
       " 'pretty',\n",
       " 'probably',\n",
       " 'problem',\n",
       " 'production',\n",
       " 'put',\n",
       " 'quality',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'read',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reason',\n",
       " 'recommend',\n",
       " 'remember',\n",
       " 'rest',\n",
       " 'right',\n",
       " 'role',\n",
       " 'run',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'scene',\n",
       " 'scenes',\n",
       " 'school',\n",
       " 'screen',\n",
       " 'script',\n",
       " 'second',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'sense',\n",
       " 'series',\n",
       " 'set',\n",
       " 'several',\n",
       " 'sex',\n",
       " 'she',\n",
       " 'short',\n",
       " 'shot',\n",
       " 'should',\n",
       " 'show',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'small',\n",
       " 'so',\n",
       " 'some',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'son',\n",
       " 'sort',\n",
       " 'sound',\n",
       " 'special',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'start',\n",
       " 'starts',\n",
       " 'still',\n",
       " 'story',\n",
       " 'stupid',\n",
       " 'style',\n",
       " 'such',\n",
       " 'supposed',\n",
       " 'sure',\n",
       " 'take',\n",
       " 'takes',\n",
       " 'tell',\n",
       " 'terrible',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'time',\n",
       " 'times',\n",
       " 'title',\n",
       " 'to',\n",
       " 'today',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'totally',\n",
       " 'town',\n",
       " 'tries',\n",
       " 'true',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'turn',\n",
       " 'turns',\n",
       " 'tv',\n",
       " 'two',\n",
       " 'under',\n",
       " 'understand',\n",
       " 'unfortunately',\n",
       " 'until',\n",
       " 'up',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 've',\n",
       " 'version',\n",
       " 'very',\n",
       " 'video',\n",
       " 'viewer',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wants',\n",
       " 'war',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'waste',\n",
       " 'watch',\n",
       " 'watched',\n",
       " 'watching',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'white',\n",
       " 'who',\n",
       " 'whole',\n",
       " 'why',\n",
       " 'wife',\n",
       " 'will',\n",
       " 'with',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'won',\n",
       " 'wonderful',\n",
       " 'work',\n",
       " 'works',\n",
       " 'world',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.74308\n",
      "F1 score: 0.7422283352049919\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10007  2493]\n",
      " [ 3930  8570]]\n"
     ]
    }
   ],
   "source": [
    "# Split data to test preprocessing and modeling techniques\n",
    "X_train, X_test, y_train, y_val = train_test_split(X, target,train_size=0.75)\n",
    "#Random forest classifier\n",
    "#Using c[] for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "     \n",
    "    #rf = RandomForestClassifier(n_estimators = 100)\n",
    "    #rf.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, rf.predict(X_test))))\n",
    "    \n",
    "final_rf = RandomForestClassifier(n_estimators = 10)\n",
    "final_rf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_rf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_rf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_rf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.84208\n",
      "F1 score: 0.8420610281179951\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10389  2111]\n",
      " [ 1837 10663]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75\n",
    "#)\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = LogisticRegression(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_log = LogisticRegression()\n",
    "final_log.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_log.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_log.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_log.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.78552\n",
      "F1 score: 0.7854882810959772\n",
      "\n",
      " Confusion Matrix:\n",
      " [[9971 2529]\n",
      " [2833 9667]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75\n",
    "#)\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#nb = MultinomialNB()\n",
    "#nb.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% ( accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_nb = MultinomialNB()\n",
    "final_nb.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_nb.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_nb.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_nb.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.83872\n",
      "F1 score: 0.83862392313888\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10179  2321]\n",
      " [ 1711 10789]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75\n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #svm = LinearSVC(C=c)\n",
    "    #svm.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.89104\n",
    "# Accuracy for C=0.05: 0.88736\n",
    "# Accuracy for C=0.25: 0.8856\n",
    "# Accuracy for C=0.5: 0.88608\n",
    "# Accuracy for C=1: 0.88592\n",
    "    \n",
    "final_svm = LinearSVC()\n",
    "final_svm.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_svm.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_svm.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_svm.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.68952\n",
      "F1 score: 0.6895183288634533\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8648 3852]\n",
      " [3910 8590]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree classifier\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75\n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #svm = DecisionTreeClassifier(C=c)\n",
    "    #svm.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.89104\n",
    "# Accuracy for C=0.05: 0.88736\n",
    "# Accuracy for C=0.25: 0.8856\n",
    "# Accuracy for C=0.5: 0.88608\n",
    "# Accuracy for C=1: 0.88592\n",
    "    \n",
    "final_dec = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "final_dec.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_dec.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_dec.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_dec.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8998\n",
      "F1 score: 0.8997972486729352\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11182  1318]\n",
      " [ 1187 11313]]\n"
     ]
    }
   ],
   "source": [
    "#n-gram feature extraction\n",
    "#Logistic Regression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words = stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_val = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#lr = LogisticRegression()\n",
    "#lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% ( accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = LogisticRegression()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.75224\n",
      "F1 score: 0.751064417043922\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10262  2238]\n",
      " [ 3956  8544]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#lr = RandomForestClassifier()\n",
    "#lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% ( accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = RandomForestClassifier(n_estimators = 10)\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88164\n",
      "F1 score: 0.8814567246992848\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11512   988]\n",
      " [ 1971 10529]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#lr = MultinomialNB()\n",
    "#lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% ( accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = MultinomialNB()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89904\n",
      "F1 score: 0.8814567246992848\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11512   988]\n",
      " [ 1971 10529]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "\n",
    "#for c in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    \n",
    "    #svm = LinearSVC(C=c)\n",
    "    #svm.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, svm.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.001: 0.88784\n",
    "# Accuracy for C=0.005: 0.89456\n",
    "# Accuracy for C=0.01: 0.89376\n",
    "# Accuracy for C=0.05: 0.89264\n",
    "# Accuracy for C=0.1: 0.8928\n",
    "    \n",
    "final = LinearSVC()\n",
    "final.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.704\n",
      "F1 score: 0.7039968154793397\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8759 3741]\n",
      " [3659 8841]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "#Using C for regularization to prevent overfitting\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "#lr = DecisionTreeClassifier()\n",
    "#lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% ( accuracy_score(y_val, lr.predict(X_test))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.88416\n",
    "# Accuracy for C=0.05: 0.892\n",
    "# Accuracy for C=0.25: 0.89424\n",
    "# Accuracy for C=0.5: 0.89456\n",
    "# Accuracy for C=1: 0.8944\n",
    "    \n",
    "final_ngram = DecisionTreeClassifier()\n",
    "final_ngram.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_ngram.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_ngram.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_ngram.predict(X_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.86752\n",
      "F1 score: 0.8675110043151665\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10947  1553]\n",
      " [ 1759 10741]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "wc_vectorizer = CountVectorizer(binary=False)\n",
    "wc_vectorizer.fit(reviews_train_clean)\n",
    "X = wc_vectorizer.transform(reviews_train_clean)\n",
    "X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75, \n",
    ")\n",
    "\n",
    "    \n",
    "# Accuracy for C=0.01: 0.87456\n",
    "# Accuracy for C=0.05: 0.88016\n",
    "# Accuracy for C=0.25: 0.87936\n",
    "# Accuracy for C=0.5: 0.87936\n",
    "# Accuracy for C=1: 0.87696\n",
    "    \n",
    "final_wc = LogisticRegression()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.75316\n",
      "F1 score: 0.7523508644987069\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10129  2371]\n",
      " [ 3800  8700]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "#wc_vectorizer = CountVectorizer(binary=False)\n",
    "#wc_vectorizer.fit(reviews_train_clean)\n",
    "#X = wc_vectorizer.transform(reviews_train_clean)\n",
    "#X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75, \n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = RandomForestClassifier(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.87456\n",
    "# Accuracy for C=0.05: 0.88016\n",
    "# Accuracy for C=0.25: 0.87936\n",
    "# Accuracy for C=0.5: 0.87936\n",
    "# Accuracy for C=1: 0.87696\n",
    "    \n",
    "final_wc = RandomForestClassifier(n_estimators = 10)\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.81512\n",
      "F1 score: 0.8143538797494231\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10992  1508]\n",
      " [ 3114  9386]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "\n",
    "#wc_vectorizer = CountVectorizer(binary=False)\n",
    "#wc_vectorizer.fit(reviews_train_clean)\n",
    "#X = wc_vectorizer.transform(reviews_train_clean)\n",
    "#X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75, \n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = MultinomialNB(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.87456\n",
    "# Accuracy for C=0.05: 0.88016\n",
    "# Accuracy for C=0.25: 0.87936\n",
    "# Accuracy for C=0.5: 0.87936\n",
    "# Accuracy for C=1: 0.87696\n",
    "    \n",
    "final_wc = MultinomialNB()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.89904\n",
      "F1 score: 0.8990378263247857\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11180  1320]\n",
      " [ 1204 11296]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "\n",
    "#wc_vectorizer = CountVectorizer(binary=False)\n",
    "#wc_vectorizer.fit(reviews_train_clean)\n",
    "#X = wc_vectorizer.transform(reviews_train_clean)\n",
    "#X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75, \n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = LinearSVC(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "    \n",
    "# Accuracy for C=0.01: 0.87456\n",
    "# Accuracy for C=0.05: 0.88016\n",
    "# Accuracy for C=0.25: 0.87936\n",
    "# Accuracy for C=0.5: 0.87936\n",
    "# Accuracy for C=1: 0.87696\n",
    "    \n",
    "final_wc = LinearSVC()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.7124\n",
      "F1 score: 0.7123870118576364\n",
      "\n",
      " Confusion Matrix:\n",
      " [[8989 3511]\n",
      " [3679 8821]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "#wc_vectorizer = CountVectorizer(binary=False)\n",
    "#wc_vectorizer.fit(reviews_train_clean)\n",
    "#X = wc_vectorizer.transform(reviews_train_clean)\n",
    "#X_val = wc_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75, \n",
    "#)\n",
    "\n",
    "\n",
    "    \n",
    "final_wc = DecisionTreeClassifier()\n",
    "final_wc.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_wc.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_wc.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_wc.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.882\n",
      "F1 score: 0.88199966695586\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11046  1454]\n",
      " [ 1496 11004]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(reviews_train_clean)\n",
    "X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "X_val = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_test, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "    \n",
    "final_tfidf = LogisticRegression()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.72832\n",
      "F1 score: 0.7267316172503767\n",
      "\n",
      " Confusion Matrix:\n",
      " [[10057  2443]\n",
      " [ 4349  8151]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer()\n",
    "#tfidf_vectorizer.fit(reviews_train_clean)\n",
    "#X = tfidf_vectorizer.transform(reviews_train_clean)\n",
    "#X_val = tfidf_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "#X_train, X_test, y_train, y_val = train_test_split(\n",
    "    #X, target, train_size = 0.75\n",
    "#)\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = RandomForestClassifier(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_test))))\n",
    "\n",
    "# Accuracy for C=0.01: 0.79632\n",
    "# Accuracy for C=0.05: 0.83168\n",
    "# Accuracy for C=0.25: 0.86768\n",
    "# Accuracy for C=0.5: 0.8736\n",
    "# Accuracy for C=1: 0.88432\n",
    "    \n",
    "final_tfidf = RandomForestClassifier(n_estimators = 10)\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.83024\n",
      "F1 score: 0.8295866203788163\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11152  1348]\n",
      " [ 2896  9604]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = MultinomialNB(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_test))))\n",
    "\n",
    "# Accuracy for C=0.01: 0.79632\n",
    "# Accuracy for C=0.05: 0.83168\n",
    "# Accuracy for C=0.25: 0.86768\n",
    "# Accuracy for C=0.5: 0.8736\n",
    "# Accuracy for C=1: 0.88432\n",
    "    \n",
    "final_tfidf = MultinomialNB()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.87704\n",
      "F1 score: 0.8770245739625577\n",
      "\n",
      " Confusion Matrix:\n",
      " [[11103  1397]\n",
      " [ 1677 10823]]\n"
     ]
    }
   ],
   "source": [
    "#Linear SVC\n",
    "\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = LinearSVC(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_test))))\n",
    "\n",
    "# Accuracy for C=0.01: 0.79632\n",
    "# Accuracy for C=0.05: 0.83168\n",
    "# Accuracy for C=0.25: 0.86768\n",
    "# Accuracy for C=0.5: 0.8736\n",
    "# Accuracy for C=1: 0.88432\n",
    "    \n",
    "final_tfidf = LinearSVC()\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "\n",
    "#for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    #lr = DecisionTreeClassifier(C=c)\n",
    "    #lr.fit(X_train, y_train)\n",
    "    #print (\"Accuracy for C=%s: %s\" \n",
    "           #% (c, accuracy_score(y_val, lr.predict(X_test))))\n",
    "\n",
    "    \n",
    "final_tfidf = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "final_tfidf.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_tfidf.predict(X_val)))\n",
    "print ('F1 score:', f1_score(target, final_tfidf.predict(X_val),\n",
    "                            average='weighted'))\n",
    "print ('\\n Confusion Matrix:\\n',confusion_matrix(target,final_tfidf.predict(X_val)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining regular expression for preprocessing\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the train and test data sets\n",
    "def load():\n",
    "\treviews_train = []\n",
    "\tfor line in open('/Users/navyasogi/Desktop/ML_Coursework/ProjectSubmission_2_Group10/movie_data/full_train.txt', 'r', encoding = \"utf8\"):\n",
    "\t\treviews_train.append(line.strip())\n",
    "\n",
    "\treviews_test = []\n",
    "\tfor line in open('/Users/navyasogi/Desktop/ML_Coursework/ProjectSubmission_2_Group10/movie_data/full_test.txt', 'r', encoding = \"utf8\"):\n",
    "\t    reviews_test.append(line.strip())\n",
    "\n",
    "\treturn(reviews_train,reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean up the cluttered review set\n",
    "def preprocess_reviews(reviews):\n",
    "\treviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "\treviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "\treturn reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test human generated review for cross validation\n",
    "def test_new_review(final_model,cv):\n",
    "\tpred = final_model.predict(cv.transform([input(\"Check Your Own Review :\")]))[0]\n",
    "\tif(pred == 0):\n",
    "\t\tprint(\"Negative Review!\")\n",
    "\telse:\n",
    "\t\tprint(\"Positive Review!\")\n",
    "\n",
    "\twhile True:\n",
    "\t\ta = input(\"Enter yes/no to continue :\")\n",
    "\t\tif a==\"yes\":\n",
    "\t\t\ttest_new_review(final_model,cv)\n",
    "\t\t\tcontinue\n",
    "\t\telif a==\"no\":\n",
    "\t\t\texit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to give example of some posetive and negative tokens\n",
    "def token_example(feature_to_coef):\n",
    "\tprint(\"Example of some positive words and their weightage:\")\n",
    "\tfor best_positive in sorted(\n",
    "\t    feature_to_coef.items(), \n",
    "\t    key=lambda x: x[1], \n",
    "\t    reverse=True)[:5]:\n",
    "\t    print (best_positive)\n",
    "    \n",
    "\tprint(\"Example of some negative words and their weightage\")\n",
    "\tfor best_negative in sorted(\n",
    "\t    feature_to_coef.items(), \n",
    "\t    key=lambda x: x[1])[:5]:\n",
    "\t    print (best_negative)\n",
    "\n",
    "def Regularisation_parameter(X_train, y_train, y_val, X_val):\n",
    "\tz = 0\n",
    "\tfor c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "\t    lr = LogisticRegression(C=c)\n",
    "\t    lr.fit(X_train, y_train)\n",
    "\t    print (\"Accuracy for C=%s: %s\" \n",
    "\t           % (c, accuracy_score(y_val, lr.predict(X_val))))\n",
    "\t    if(z < accuracy_score(y_val, lr.predict(X_val))):\n",
    "\t    \tz = accuracy_score(y_val, lr.predict(X_val))\n",
    "\t\n",
    "\treturn z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navyasogi/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87376\n",
      "Accuracy for C=0.05: 0.88272\n",
      "Accuracy for C=0.25: 0.88112\n",
      "Accuracy for C=0.5: 0.8792\n",
      "Accuracy for C=1: 0.87664\n",
      "Final Accuracy: 0.86996\n",
      "Example of some positive words and their weightage:\n",
      "('excellent', 1.5309132069840166)\n",
      "('refreshing', 1.4788910507307105)\n",
      "('perfect', 1.3514897566777184)\n",
      "('appreciated', 1.3426913896260355)\n",
      "('superb', 1.3064091359245487)\n",
      "Example of some negative words and their weightage\n",
      "('worst', -2.29806508036418)\n",
      "('waste', -2.136582853316402)\n",
      "('disappointment', -1.9421043741655781)\n",
      "('poorly', -1.9177267225731687)\n",
      "('awful', -1.720104577480633)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\t#loading the train and test data sets\n",
    "\treviews_train,reviews_test = load()\n",
    "\n",
    "\t#preprocessing the given data\n",
    "\treviews_train_clean = preprocess_reviews(reviews_train)\n",
    "\treviews_test_clean = preprocess_reviews(reviews_test)\n",
    "\n",
    "\n",
    "\t#vectorization of the reviews\n",
    "\tcv = CountVectorizer(binary=True)\n",
    "\tcv.fit(reviews_train_clean) \n",
    "\tX = cv.transform(reviews_train_clean) # will give a sparse matrix find a way to make this efficient\n",
    "\tX_test = cv.transform(reviews_test_clean)\n",
    "\ttarget = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "\n",
    "\t#splitting the train and test data\n",
    "\tX_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75)\n",
    "\n",
    "\t#choosing the regularisaton parameter (logistic regression) for the greatest accuracy value\n",
    "\tbest_c_value = Regularisation_parameter(X_train, y_train, y_val, X_val)\n",
    "\n",
    "\t#training the final logistic model for the best accuracy\n",
    "\tfinal_model = LogisticRegression(C=best_c_value)\n",
    "\tfinal_model.fit(X, target)\n",
    "\tprint (\"Final Accuracy: %s\" \n",
    "\t       % accuracy_score(target, final_model.predict(X_test)))\n",
    "\n",
    "\tfeature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "\t}\n",
    "\n",
    "    #example of pos and neg sentiment\n",
    "\ttoken_example(feature_to_coef) \n",
    "\t\n",
    "\twhile(True):\n",
    "\t\ttest_new_review(final_model,cv) #checking the model with human data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
